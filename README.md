# MockMate-AI â€” Resume to Interviewer (Hackathon MVP)

MockMate-AI is a hackathon-ready MVP that converts a candidate's resume into a tailored interviewer persona and runs a simulated interview with live questions and feedback. This project is optimized for quick demos and can use a small local LLM (llama-cpp-python) or OpenAI as a fallback. It also includes optional offline TTS for question playback.

## ğŸš€ Key Features

| Feature | Description |
|----------|-------------|
| ğŸ§¾ **Resume Parsing** | Automatically extracts name, skills, experience, and summary from `.pdf` or `.docx` resumes. |
| ğŸ§  **Persona Builder** | Creates a mock interviewer persona based on your role, seniority, and technical stack. |
| ğŸ¤ **Voice Mode (Optional)** | Supports TTS via **pyttsx3** or **ElevenLabs**; allows microphone-based interaction (if enabled). |
| ğŸ’¬ **Conversational AI** | Uses a local lightweight LLM (Llama-cpp or Gemma-mini) for offline, latency-free mock interviews. |
| ğŸª„ **Feedback Generator** | Provides personalized feedback and improvement suggestions after each mock round. |
| ğŸŒ **Offline First** | Runs fully offline with local models and minimal dependencies (perfect for hackathon demos). |

---

## Repo Structure
```
mockmate-ai/
â”œâ”€â”€ app.py
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ requirements-lite.txt
â”œâ”€â”€ setup.sh
â”œâ”€â”€ .env.example
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ parser.py
â”‚   â”œâ”€â”€ persona_builder.py
â”‚   â”œâ”€â”€ llm_wrapper.py
â”‚   â”œâ”€â”€ interviewer_agent.py
â”‚   â””â”€â”€ feedback_generator.py
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ prompt_templates.py
â””â”€â”€ data/
    â””â”€â”€ samples/
```

## âš™ï¸ Setup

### ğŸ§© 1. Clone the Repository
```bash
git clone https://github.com/<username>/mockmate-ai.git
cd mockmate-ai
```

### ğŸ§© 2. Run Lightweight Setup Script
```bash
bash setup.sh
```

### ğŸ§© 3. Run the App
```bash
streamlit run app.py
```

## ğŸ™ï¸ Optional: Enable ElevenLabs Voice Output

If you want lifelike AI interviewer voice, add your ElevenLabs API key in .env:
```bash
ELEVENLABS_API_KEY=your_api_key_here
USE_ELEVENLABS_TTS=true
```

The system will gracefully fall back to pyttsx3 if unavailable.

## ğŸ§  Model Configuration

By default, the system uses a lightweight local LLM:

- llama-cpp-python (for Llama 2/3 GGUF models)
- Optional: HuggingFace Transformers backend for online use

To use a specific model, update .env:
```bash
LLM_MODEL_PATH=models/llama-2-7b.gguf
```

You can also switch to Ollama or Gemma-mini with minimal code change in llm_wrapper.py.

## ğŸ§© Supported Skills (Sample)

#### Technical Skills:
`AS400, RPGLE, IBMi, SYNON, Spring Boot, REST, Microservices, AWS`

#### Role-Based Skills:
`Project Management, Team Mentoring, Stakeholder Management, Agile Delivery, Requirement Estimation, Delivery Planning`

The interviewer dynamically generates relevant questions from these.

## ğŸ§ª Example Interaction
```
ğŸ‘©â€ğŸ’¼ AI Interviewer: Hi there! I noticed youâ€™ve got solid AS400 and Spring Boot experience.
Could you walk me through how you integrated legacy IBM i systems with modern microservices?

ğŸ§‘ Candidate: Sure, we used message queues with SQS and built REST interfaces using Spring Boot...

ğŸ‘©â€ğŸ’¼ AI Interviewer: Interesting. What was your approach to transaction reliability and retry logic?

ğŸ’¬ Feedback: Good coverage! You might elaborate on SQS DLQs and error handling patterns next time.
```
